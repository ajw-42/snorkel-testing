{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "\n",
    "- I installed snorkel from the redux branch on 7 Aug into an environment running Python 3.6 -- 3.5 and 3.7 both didn't work for me. Skimming the git issues seems to indicate this is going to be fixed.\n",
    "- Snorkel developers are working on a new release - \"coming later this summer\" - so it may soon be better to install from master or just with pip/conda\n",
    "- For data, I'm using the version of the Global Terrorism Database on Kaggle (https://www.kaggle.com/START-UMD/gtd/)\n",
    "\n",
    "Beware of blogs, etc. about snorkel which may be helpful but often discuss outdated versions of the API!\n",
    "- These tutorials WERE helpful, and then they got deleted: https://github.com/HazyResearch/snorkel/tree/redux/tutorials/workshop.\n",
    "- Avoid these tutorials, which are outdated: https://github.com/HazyResearch/snorkel/blob/master/tutorials\n",
    "- These tutorials seem to be up-to-date. I recommend the YouTube spam tutorial for basics on text classification: https://github.com/snorkel-team/snorkel-tutorials/blob/master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import snorkel\n",
    "import re \n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/snorkel2/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (4,6,31,33,61,62,63,76,79,90,92,94,96,114,115,121) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "terror_df = pd.read_csv('/Users/awhite/Documents/globalterrorismdb_0718dist.csv',\n",
    "                       encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                   NaN\n",
       "1                                                   NaN\n",
       "2                                                   NaN\n",
       "3                                                   NaN\n",
       "4                                                   NaN\n",
       "5     1/1/1970: Unknown African American assailants ...\n",
       "6                                                   NaN\n",
       "7     1/2/1970: Unknown perpetrators detonated explo...\n",
       "8     1/2/1970: Karl Armstrong, a member of the New ...\n",
       "9     1/3/1970: Karl Armstrong, a member of the New ...\n",
       "10                                                  NaN\n",
       "11    1/6/1970: Unknown perpetrators threw a Molotov...\n",
       "12                                                  NaN\n",
       "13    1/9/1970: Unknown perpetrators set off a fireb...\n",
       "14    1/9/1970:  The Armed Commandos of Liberation c...\n",
       "15                                                  NaN\n",
       "16                                                  NaN\n",
       "17    1/12/1970: Unknown perpetrators threw a pipe b...\n",
       "18    1/12/1970: Unknown perpetrators detonated a bo...\n",
       "19    1/13/1970: Unknown perpetrators firebombed Fus...\n",
       "Name: summary, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terror_df.summary.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115562"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop items w no summary\n",
    "terror_df = terror_df.dropna(subset=['summary'])\n",
    "len(terror_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(terror_df, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#snorkel calls for a separate validation set (and optionally a dev set for LF development)\n",
    "train, valid = train_test_split(train, test_size = 0.2, random_state = 0)\n",
    "\n",
    "Y_train = train[\"suicide\"].values\n",
    "Y_valid = valid[\"suicide\"].values\n",
    "Y_test = test[\"suicide\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23113"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to predict if an attack was a suicide attack - this seems easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76962    09/04/2004: A Police Academy in Kirkuk Iraq was attacked by a suicide bomber in a car, killing 20 and wounding 36. Tawhid and Jihad claimed responsibility for the attack.                                                                                                                                                                                                                                                                                       \n",
       "76226    01/18/2004: A pickup truck loaded with 500 kilos of explosives exploded at the Assassin's Gate, the entrance to the main industrial center of Baghdad, Iraq, and also the United States' Military headquarters. Twenty-five were people killed and over 100 were injured in the attack, for which no group claimed responsibility.                                                                                                                               \n",
       "77565    02/24/2005: An unidentified suicide car bomber wearing a police uniform targeted police headquarters in Tikrit, Iraq. The explosion killed 10 people and wounded 35 others. No group claimed responsibility for the bombing.                                                                                                                                                                                                                                     \n",
       "85300    12/15/2007: An unidentified suicide bomber on a bike detonated himself outside a military checkpoint in the city of Nowshera, Pakistan, killing two soldiers and three civilians. Several others were injured in the blast.                                                                                                                                                                                                                                      \n",
       "85331    12/23/2007:  In Mingaora, Pakistan, a sucicide bomber detonated his vehicle-borne improvised explosive devide (VBIED) near a military convoy.  Six civillians were killed, along with four soldiers and three children.  Fifteen soldiers were wounded along with 11 civillians.  Damages were suffered toward four civillain vehicle, two military vehicles, 14 shops, and to nearby electric lines.  The Thrik-i-Taliban Pakistan (TTP) claimed responsibility.\n",
       "Name: summary, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 0)\n",
    "\n",
    "terror_df[terror_df.suicide == 1].summary.sample(5, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112007    10/30/2012: Assailants detonated an explosive device at an electricity tower in the Ghitani area of Mach town, Balochistan province, Pakistan. There were no reported casualties; however, the targeted tower was partially damaged in the blast. No group claimed responsibility for the incident.                                                                                                               \n",
       "156272    12/05/2015: An explosive device detonated as police personnel were attempting to defuse it in Waghaz district, Ghazni Province, Afghanistan. Two police officers were wounded in the blast. No group claimed responsibility for the incident.                                                                                                                                                                     \n",
       "158353    01/31/2016: Explosive devices detonated targeting a military patrol in eastern Norte de Santander department, Colombia. Two soldiers were killed in the blast. No group claimed responsibility for the incident; however, sources attributed the attack to the National Liberation Army of Colombia (ELN).                                                                                                        \n",
       "139260    10/16/2014: Assailants opened fire on Ukrainian Army soldiers near Tonenke town, Donetsk oblast, Ukraine. There were no reported casualties in the attack. No group claimed responsibility for the incident; however, sources attributed the attack to the Donetsk People's Republic.                                                                                                                             \n",
       "104356    12/1/2011: On a road in Ban Buathong in the Than To district of Yala, Thailand, a soldier was killed when he stepped on a landmine.  The soldier, Pvt. Kriangkrai Promsai, was part of a nine person patrol in the area.  Another soldier, Pvt. Siam Saw Lao, was injured in the blast.  While there was no claim of responsibility, it is believed that Runda Kumpulan Kecil (RKK) is responsible for the attack.\n",
       "Name: summary, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "terror_df[terror_df.suicide == 0].summary.sample(5, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.apply import PandasLFApplier\n",
    "from snorkel.labeling.lf import labeling_function\n",
    "from snorkel.types import DataPoint\n",
    "\n",
    "POS = 1\n",
    "NEG = 0 \n",
    "ABSTAIN = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    73772\n",
       "True     187  \n",
       "Name: summary, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.summary.str.contains(\"suicide attack\").value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems snorkel isn't very forgiving about the way you write LFs. I tried a number of different ways for these basic examples - find a substring in text - and couldn't get them to work until I copied the approach in https://github.com/snorkel-team/snorkel-tutorials/blob/master/spam/01_spam_tutorial.ipynb. For instance `str.contains()` and `str.count()` didn't work. Maybe I was doing something wrong.\n",
    "\n",
    "While there is some disagreement on this, snorkel developers generally suggest that many simple LFs are better than a few complex LFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def suicide_mentioned(x):\n",
    "    return POS if \"suicide\" in x.summary.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def suicide_attack(x):\n",
    "    return POS if \"suicide attack\" in x.summary.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def suicide_bomb(x):\n",
    "    return POS if \"suicide bomb\" in x.summary.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def unknown_perps(x):\n",
    "    return NEG if \"unknown perpetrator\" in x.summary.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def no_responsibility(x):\n",
    "    return NEG if \"no group claimed responsibility\" in x.summary.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`PandasLFApplier` is what it sounds like - a snorkel tool for applying LFs to a pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73959/73959 [00:10<00:00, 6797.23it/s]\n",
      "100%|██████████| 18490/18490 [00:02<00:00, 6961.96it/s]\n",
      "100%|██████████| 23113/23113 [00:03<00:00, 6852.17it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [suicide_mentioned,suicide_attack,\n",
    "       suicide_bomb,unknown_perps,\n",
    "       no_responsibility]\n",
    "\n",
    "applier = PandasLFApplier(lfs)\n",
    "\n",
    "L_train = applier.apply(df=train)\n",
    "L_valid = applier.apply(df=valid)\n",
    "L_test = applier.apply(df=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>suicide_mentioned</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.053678</td>\n",
       "      <td>0.051082</td>\n",
       "      <td>0.025392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide_attack</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.001028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide_bomb</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.048581</td>\n",
       "      <td>0.048581</td>\n",
       "      <td>0.023540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown_perps</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_responsibility</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.658203</td>\n",
       "      <td>0.026488</td>\n",
       "      <td>0.025352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts\n",
       "suicide_mentioned  0  [1]      0.053678  0.051082  0.025392 \n",
       "suicide_attack     1  [1]      0.002555  0.002555  0.001028 \n",
       "suicide_bomb       2  [1]      0.048581  0.048581  0.023540 \n",
       "unknown_perps      3  [0]      0.016104  0.001176  0.000041 \n",
       "no_responsibility  4  [0]      0.658203  0.026488  0.025352 "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling.analysis import LFAnalysis\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you supply gold labels, snorkel calculates empirical accuracy for you. We're cheating here by using training set labels, but this is the purpose of the dev set - a small pool of data that is labeled, possibly just by hand.\n",
    "\n",
    "https://medium.com/sculpt/a-technique-for-building-nlp-classifiers-efficiently-with-transfer-learning-and-weak-supervision-a8e2f21ca9c8 is a good resource here - the author talks about hand-labeling data and building LFs when using snorkel to identify anti-semitic tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>suicide_mentioned</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.053678</td>\n",
       "      <td>0.051082</td>\n",
       "      <td>0.025392</td>\n",
       "      <td>3878</td>\n",
       "      <td>92</td>\n",
       "      <td>0.976826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide_attack</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>180</td>\n",
       "      <td>9</td>\n",
       "      <td>0.952381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide_bomb</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.048581</td>\n",
       "      <td>0.048581</td>\n",
       "      <td>0.023540</td>\n",
       "      <td>3535</td>\n",
       "      <td>58</td>\n",
       "      <td>0.983858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unknown_perps</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1188</td>\n",
       "      <td>3</td>\n",
       "      <td>0.997481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_responsibility</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.658203</td>\n",
       "      <td>0.026488</td>\n",
       "      <td>0.025352</td>\n",
       "      <td>46764</td>\n",
       "      <td>1916</td>\n",
       "      <td>0.960641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "suicide_mentioned  0  [1]      0.053678  0.051082  0.025392   3878      \n",
       "suicide_attack     1  [1]      0.002555  0.002555  0.001028   180       \n",
       "suicide_bomb       2  [1]      0.048581  0.048581  0.023540   3535      \n",
       "unknown_perps      3  [0]      0.016104  0.001176  0.000041   1188      \n",
       "no_responsibility  4  [0]      0.658203  0.026488  0.025352   46764     \n",
       "\n",
       "                   Incorrect  Emp. Acc.  \n",
       "suicide_mentioned  92         0.976826   \n",
       "suicide_attack     9          0.952381   \n",
       "suicide_bomb       58         0.983858   \n",
       "unknown_perps      3          0.997481   \n",
       "no_responsibility  1916       0.960641   "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you supply gold labels, snorkel calculates empirical accuracy for you!\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary(Y=Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in theory we should stop here, because LFs by themselves give good accuracy. Or, if the description says suicide bomber...it's probably a suicide bomber. But let's work through to the end for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First, let's try a simple majority vote approach\n",
    "from snorkel.labeling.model import MajorityLabelVoter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority_model = MajorityLabelVoter()\n",
    "Y_pred_train = majority_model.predict(L=L_train)\n",
    "Y_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   85.2%\n"
     ]
    }
   ],
   "source": [
    "majority_acc = majority_model.score(L=L_valid, Y=Y_valid)[\"accuracy\"]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's use snorkel's model for probabilistic labels and train a classifier \n",
    "from snorkel.labeling.model import LabelModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=1000, lr=0.001, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Model Accuracy:     83.7%\n"
     ]
    }
   ],
   "source": [
    "label_model_acc = label_model.score(L=L_valid, Y=Y_valid)[\"accuracy\"]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label model usually outperforms the majority vote model - that isn't the case here because we have a few super accurate LFs. Snorkel also warns against using the label model for prediction: \n",
    "\n",
    ">it is typically not suitable as an inference-time model to make predictions for unseen examples, due to (among other things) some data points having all abstain labels. \n",
    "\n",
    "Next, let's check to be sure the labels are probabilistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot_probabilities_histogram(Y):\n",
    "    plt.hist(Y, bins=10)\n",
    "    plt.xlabel(\"Probability that incident is suicide attack\")\n",
    "    plt.ylabel(\"Number of data points\")\n",
    "    plt.show()\n",
    "\n",
    "Y_probs_train = label_model.predict_proba(L=L_train)\n",
    "plot_probabilities_histogram(Y_probs_train[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original dataset is unbalanced so that looks about right.\n",
    "\n",
    "`filtered_unlabeled_dataframe` cuts any rows that didn't get labels from the training set, as another way to boost performance. It's mentioned in the snorkel tutorials but the function is not exactly where the tutorials claim - I found this and `probs_to_pred` by searching for the functions in the snorkel GH. This code might not run in the future if snorkel is updated to match the tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.utils import filter_unlabeled_dataframe\n",
    "\n",
    "train_filtered, Y_probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=train, y=Y_probs_train, L=L_train\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "words_train = [row.summary for i, row in train_filtered.iterrows()]\n",
    "words_valid = [row.summary for i, row in valid.iterrows()]\n",
    "words_test = [row.summary for i, row in test.iterrows()]\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train = vectorizer.fit_transform(words_train)\n",
    "X_valid = vectorizer.transform(words_valid)\n",
    "X_test = vectorizer.transform(words_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn doesn't accept probabilistic labels, so snorkel provides a helper function to replace each label distribution with the label of the class that has the maximum probability. This is less good, but let's try for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.analysis.utils import probs_to_preds\n",
    "Y_preds_train_filtered = probs_to_preds(probs=Y_probs_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(X_train, Y_preds_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9391251676545667"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = classifier.predict(X_test)\n",
    "np.mean(predicted == Y_test)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9710985159866742"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier().fit(X_train, Y_preds_train_filtered)\n",
    "\n",
    "predicted = classifier.predict(X_test)\n",
    "np.mean(predicted == Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're close to the performance of individual LFs...but not quite there.\n",
    "\n",
    "Finally, let's quickly test snorkel's claim that dropping unlabeled items boosts performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_preds_train = probs_to_preds(probs=Y_probs_train)\n",
    "\n",
    "words_train = [row.summary for i, row in train.iterrows()]\n",
    "words_valid = [row.summary for i, row in valid.iterrows()]\n",
    "words_test = [row.summary for i, row in test.iterrows()]\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "X_train = vectorizer.fit_transform(words_train)\n",
    "X_valid = vectorizer.transform(words_valid)\n",
    "X_test = vectorizer.transform(words_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9711850473759356"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = SGDClassifier().fit(X_train, Y_preds_train)\n",
    "\n",
    "predicted = classifier.predict(X_test)\n",
    "np.mean(predicted == Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least in this case, basically the same performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
