{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to identify articles about the Syrian conflict in the same dataset of Arabic news. A few notes on findings here...\n",
    "\n",
    "- According to some quick testing at the end of this notebook, snorkel appears to perform best when you have one LF in which you're fairly confident, and get high or complete coverage for this LF - i.e. abstain rarely or not at all. Probably would be useful to think more about when this is/isn't true.\n",
    "- With that in mind, I haven't yet found a case where snorkel's tool for dropping unlabeled rows improves performance much - because getting high coverage (w solid accuracy!) is important.\n",
    "- Of course, this could really just mean that I need to write better labeling functions. Iterative testing and tweaking of LFs is defnitely important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import re\n",
    "import snorkel\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.apply import PandasLFApplier\n",
    "from snorkel.labeling.lf import labeling_function\n",
    "\n",
    "POS = 1\n",
    "NEG = 0\n",
    "ABSTAIN = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>syria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>روحاني سوريا اخير جددت طهران تاكيد ستواصل لدمش...</td>\n",
       "      <td>الأزمة_السورية</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>اشنطن ترفض تعاون مكافحه ارهاب اعلنت متحدثه باس...</td>\n",
       "      <td>الأزمة_السورية</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>دمشق تطلب موسكو تنظيم جوله مشاورات ثالثه معارض...</td>\n",
       "      <td>الأزمة_السورية</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>صحيفه جمهوريت توكد تورط تركيا ادخال مسلحين سور...</td>\n",
       "      <td>الأزمة_السورية</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>امكانيه روسيا يجتمع مقاطعه بافاريا المانيه قاد...</td>\n",
       "      <td>الأزمة_السورية</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text         category  \\\n",
       "1479  روحاني سوريا اخير جددت طهران تاكيد ستواصل لدمش...  الأزمة_السورية   \n",
       "1480  اشنطن ترفض تعاون مكافحه ارهاب اعلنت متحدثه باس...  الأزمة_السورية   \n",
       "1481  دمشق تطلب موسكو تنظيم جوله مشاورات ثالثه معارض...  الأزمة_السورية   \n",
       "1482  صحيفه جمهوريت توكد تورط تركيا ادخال مسلحين سور...  الأزمة_السورية   \n",
       "1483  امكانيه روسيا يجتمع مقاطعه بافاريا المانيه قاد...  الأزمة_السورية   \n",
       "\n",
       "      syria  \n",
       "1479      1  \n",
       "1480      1  \n",
       "1481      1  \n",
       "1482      1  \n",
       "1483      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_df = pd.read_csv('/Users/awhite/Documents/GitHub/snorkel-testing/arabic_news_cleaned.csv')\n",
    "\n",
    "media_df = media_df.assign(syria = media_df.category.str.contains(\"سورية\") == True)\n",
    "media_df.syria = media_df.syria.replace({True:1,False:0})\n",
    "\n",
    "media_df[media_df.syria == 1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14166"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(media_df, test_size = 0.2, random_state = 0)\n",
    "\n",
    "train, valid = train_test_split(train, test_size = 0.2, random_state = 0)\n",
    "train, dev = train_test_split(train, test_size = 0.2, random_state = 0)\n",
    "\n",
    "Y_train = train[\"syria\"].values\n",
    "Y_dev = dev[\"syria\"].values\n",
    "Y_valid = valid[\"syria\"].values\n",
    "Y_test = test[\"syria\"].values\n",
    "\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try with no time-dependent info about the conflict\n",
    "#so groups that might change their name or disban aren't allowed in LFs\n",
    "\n",
    "provinces = r\"ريف دمشق|السويداء|دمشق|طرطوس|درعا|دير الزور|حلب|حماة|الحسكة|حمص|ادلب|القنيطرة|اللاذقية|الرقة\"\n",
    "syria_terms = r\"معارض|محرر|نظام|اسد\"\n",
    "regional_players = r\"تركي|لبنان|اسرئيل|اردن\"\n",
    "politics = r\"سياسي|اتفاق|مفاوضات|وفد|بعثة\"\n",
    "war = r\"حرب|اهلي|اطلاق النار|اشتباك|صراع|معارك|اسلاح|سلح\"\n",
    "\n",
    "\n",
    "#Exclusion terms idea didn't work well for oil - but if Syria isn't mentioned at all,\n",
    "#probably isn't about Syria\n",
    "@labeling_function()\n",
    "def syria(x):\n",
    "    return POS if re.search(r\"سوريا|سوري\", x.text) and re.search(syria_terms, x.text) else NEG\n",
    "\n",
    "@labeling_function()\n",
    "def provinces_mention(x):\n",
    "    return POS if re.search(provinces, x.text) else ABSTAIN \n",
    "\n",
    "@labeling_function()\n",
    "def regional_politics(x):\n",
    "    return POS if re.search(r\"سوريا|سوري\", x.text) and re.search(regional_players, x.text) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def syria_politics(x):\n",
    "    return POS if re.search(r\"سوريا|سوري\", x.text) and re.search(politics, x.text) else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def syria_war(x):\n",
    "    return POS if re.search(r\"سوريا|سوري\", x.text) and re.search(war, x.text) else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14166/14166 [00:02<00:00, 4885.48it/s]\n",
      "100%|██████████| 3542/3542 [00:00<00:00, 5141.23it/s]\n",
      "100%|██████████| 4428/4428 [00:00<00:00, 5091.47it/s]\n",
      "100%|██████████| 5534/5534 [00:01<00:00, 5009.98it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [syria,provinces_mention,regional_politics,\n",
    "       syria_politics,syria_war]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=train)\n",
    "L_dev = applier.apply(df=dev)\n",
    "L_valid = applier.apply(df=valid)\n",
    "L_test = applier.apply(df=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>syria</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.230661</td>\n",
       "      <td>0.137775</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0.892998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>provinces_mention</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.081310</td>\n",
       "      <td>0.081310</td>\n",
       "      <td>0.042349</td>\n",
       "      <td>193</td>\n",
       "      <td>95</td>\n",
       "      <td>0.670139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regional_politics</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.094862</td>\n",
       "      <td>0.094862</td>\n",
       "      <td>0.058159</td>\n",
       "      <td>180</td>\n",
       "      <td>156</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syria_politics</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.102767</td>\n",
       "      <td>0.102767</td>\n",
       "      <td>0.044890</td>\n",
       "      <td>257</td>\n",
       "      <td>107</td>\n",
       "      <td>0.706044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syria_war</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.140599</td>\n",
       "      <td>0.140599</td>\n",
       "      <td>0.075381</td>\n",
       "      <td>320</td>\n",
       "      <td>178</td>\n",
       "      <td>0.642570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "syria              0   [0, 1]  1.000000  0.230661   0.137775      266   \n",
       "provinces_mention  1      [1]  0.081310  0.081310   0.042349      193   \n",
       "regional_politics  2      [1]  0.094862  0.094862   0.058159      180   \n",
       "syria_politics     3      [1]  0.102767  0.102767   0.044890      257   \n",
       "syria_war          4      [1]  0.140599  0.140599   0.075381      320   \n",
       "\n",
       "                   Incorrect  Emp. Acc.  \n",
       "syria                      0   0.892998  \n",
       "provinces_mention         95   0.670139  \n",
       "regional_politics        156   0.535714  \n",
       "syria_politics           107   0.706044  \n",
       "syria_war                178   0.642570  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.labeling.analysis import LFAnalysis\n",
    "\n",
    "LFAnalysis(L=L_dev, lfs=lfs).lf_summary(Y=Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   89.2%\n",
      "Label Model Accuracy:     88.6%\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "majority_model = MajorityLabelVoter()\n",
    "Y_pred_train = majority_model.predict(L=L_train)\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=1000, lr=0.001, log_freq=100, seed=123)\n",
    "\n",
    "majority_acc = majority_model.score(L=L_valid, Y=Y_valid)[\"accuracy\"]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "label_model_acc = label_model.score(L=L_valid, Y=Y_valid)[\"accuracy\"]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not seeing a performance jump from the label model here. Could this be another rule of thumb indicator that more work on LFs is needed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.utils import filter_unlabeled_dataframe\n",
    "from snorkel.analysis.utils import probs_to_preds\n",
    "\n",
    "Y_probs_train = label_model.predict_proba(L=L_train)\n",
    "\n",
    "train_filtered, Y_probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=train, y=Y_probs_train, L=L_train)\n",
    "\n",
    "Y_preds_train_filtered = probs_to_preds(probs=Y_probs_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "words_train = [row.text for i, row in train_filtered.iterrows()]\n",
    "words_valid = [row.text for i, row in valid.iterrows()]\n",
    "words_test = [row.text for i, row in test.iterrows()]\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "X_train = vectorizer.fit_transform(words_train)\n",
    "X_valid = vectorizer.transform(words_valid)\n",
    "X_test = vectorizer.transform(words_test)\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier().fit(X_train, Y_preds_train_filtered)\n",
    "\n",
    "classifier.score(X_test, Y_test)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run a few more tests. First, what happens if we drop our best LF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14166/14166 [00:02<00:00, 5727.57it/s]\n",
      "100%|██████████| 3542/3542 [00:00<00:00, 5477.27it/s]\n",
      "100%|██████████| 4428/4428 [00:00<00:00, 5962.38it/s]\n",
      "100%|██████████| 5534/5534 [00:01<00:00, 5348.23it/s]\n"
     ]
    }
   ],
   "source": [
    "lfs = [provinces_mention,regional_politics,\n",
    "       syria_politics,syria_war]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=train)\n",
    "L_dev = applier.apply(df=dev)\n",
    "L_valid = applier.apply(df=valid)\n",
    "L_test = applier.apply(df=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>provinces_mention</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.081310</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193</td>\n",
       "      <td>95</td>\n",
       "      <td>0.670139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regional_politics</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.094862</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180</td>\n",
       "      <td>156</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syria_politics</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.102767</td>\n",
       "      <td>0.076793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257</td>\n",
       "      <td>107</td>\n",
       "      <td>0.706044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syria_war</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.140599</td>\n",
       "      <td>0.102484</td>\n",
       "      <td>0.0</td>\n",
       "      <td>320</td>\n",
       "      <td>178</td>\n",
       "      <td>0.642570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "provinces_mention  0      [1]  0.081310  0.071429        0.0      193   \n",
       "regional_politics  1      [1]  0.094862  0.071429        0.0      180   \n",
       "syria_politics     2      [1]  0.102767  0.076793        0.0      257   \n",
       "syria_war          3      [1]  0.140599  0.102484        0.0      320   \n",
       "\n",
       "                   Incorrect  Emp. Acc.  \n",
       "provinces_mention         95   0.670139  \n",
       "regional_politics        156   0.535714  \n",
       "syria_politics           107   0.706044  \n",
       "syria_war                178   0.642570  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_dev, lfs=lfs).lf_summary(Y=Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   50.4%\n",
      "Label Model Accuracy:     50.4%\n"
     ]
    }
   ],
   "source": [
    "majority_model = MajorityLabelVoter()\n",
    "Y_pred_train = majority_model.predict(L=L_train)\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=1000, lr=0.001, log_freq=100, seed=123)\n",
    "\n",
    "majority_acc = majority_model.score(L=L_valid, Y=Y_valid)[\"accuracy\"]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "label_model_acc = label_model.score(L=L_valid, Y=Y_valid)[\"accuracy\"]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 91.3%\n"
     ]
    }
   ],
   "source": [
    "Y_probs_train = label_model.predict_proba(L=L_train)\n",
    "\n",
    "train_filtered, Y_probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=train, y=Y_probs_train, L=L_train)\n",
    "\n",
    "Y_preds_train_filtered = probs_to_preds(probs=Y_probs_train_filtered)\n",
    "      \n",
    "words_train = [row.text for i, row in train_filtered.iterrows()]\n",
    "words_valid = [row.text for i, row in valid.iterrows()]\n",
    "words_test = [row.text for i, row in test.iterrows()]\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "X_train = vectorizer.fit_transform(words_train)\n",
    "X_valid = vectorizer.transform(words_valid)\n",
    "X_test = vectorizer.transform(words_test)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(X_train, Y_preds_train_filtered)\n",
    "      \n",
    "print(f\"Test Accuracy: {classifier.score(X=X_test, y=Y_test) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about ignoring snorkel's advice to drop unlabeled rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   50.4%\n",
      "Label Model Accuracy:     50.4%\n",
      "Test Accuracy: 20.3%\n"
     ]
    }
   ],
   "source": [
    "majority_model = MajorityLabelVoter()\n",
    "Y_pred_train = majority_model.predict(L=L_train)\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=1000, lr=0.001, log_freq=100, seed=123)\n",
    "\n",
    "majority_acc = majority_model.score(L=L_valid, Y=Y_valid)[\"accuracy\"]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "label_model_acc = label_model.score(L=L_valid, Y=Y_valid)[\"accuracy\"]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")\n",
    "      \n",
    "Y_probs_train = label_model.predict_proba(L=L_train)\n",
    "\n",
    "Y_preds_train = probs_to_preds(probs=Y_probs_train)\n",
    "      \n",
    "words_train = [row.text for i, row in train.iterrows()]\n",
    "words_valid = [row.text for i, row in valid.iterrows()]\n",
    "words_test = [row.text for i, row in test.iterrows()]\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "X_train = vectorizer.fit_transform(words_train)\n",
    "X_valid = vectorizer.transform(words_valid)\n",
    "X_test = vectorizer.transform(words_test)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(X_train, Y_preds_train)\n",
    "      \n",
    "print(f\"Test Accuracy: {classifier.score(X=X_test, y=Y_test) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, what about increasing our confidence in the (second) best LF by having it return negative instead of abstaining?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14166/14166 [00:02<00:00, 5924.81it/s]\n",
      "100%|██████████| 3542/3542 [00:00<00:00, 5715.12it/s]\n",
      "100%|██████████| 4428/4428 [00:00<00:00, 5966.24it/s]\n",
      "100%|██████████| 5534/5534 [00:00<00:00, 5992.04it/s]\n"
     ]
    }
   ],
   "source": [
    "@labeling_function()\n",
    "def syria_politics2(x):\n",
    "    return POS if re.search(r\"سوريا|سوري\", x.text) and re.search(politics, x.text) else NEG\n",
    "\n",
    "lfs = [provinces_mention,regional_politics,\n",
    "       syria_politics2,syria_war]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=train)\n",
    "L_dev = applier.apply(df=dev)\n",
    "L_valid = applier.apply(df=valid)\n",
    "L_test = applier.apply(df=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>provinces_mention</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.081310</td>\n",
       "      <td>0.081310</td>\n",
       "      <td>0.045737</td>\n",
       "      <td>193</td>\n",
       "      <td>95</td>\n",
       "      <td>0.670139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regional_politics</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.094862</td>\n",
       "      <td>0.094862</td>\n",
       "      <td>0.056183</td>\n",
       "      <td>180</td>\n",
       "      <td>156</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syria_politics2</th>\n",
       "      <td>2</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.204687</td>\n",
       "      <td>0.127894</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>0.883964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syria_war</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.140599</td>\n",
       "      <td>0.140599</td>\n",
       "      <td>0.090627</td>\n",
       "      <td>320</td>\n",
       "      <td>178</td>\n",
       "      <td>0.642570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "provinces_mention  0      [1]  0.081310  0.081310   0.045737      193   \n",
       "regional_politics  1      [1]  0.094862  0.094862   0.056183      180   \n",
       "syria_politics2    2   [0, 1]  1.000000  0.204687   0.127894      257   \n",
       "syria_war          3      [1]  0.140599  0.140599   0.090627      320   \n",
       "\n",
       "                   Incorrect  Emp. Acc.  \n",
       "provinces_mention         95   0.670139  \n",
       "regional_politics        156   0.535714  \n",
       "syria_politics2            0   0.883964  \n",
       "syria_war                178   0.642570  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_dev, lfs=lfs).lf_summary(Y=Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   89.1%\n",
      "Label Model Accuracy:     88.5%\n"
     ]
    }
   ],
   "source": [
    "majority_model = MajorityLabelVoter()\n",
    "Y_pred_train = majority_model.predict(L=L_train)\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=1000, lr=0.001, log_freq=100, seed=123)\n",
    "\n",
    "majority_acc = majority_model.score(L=L_valid, Y=Y_valid)[\"accuracy\"]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "label_model_acc = label_model.score(L=L_valid, Y=Y_valid)[\"accuracy\"]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 91.3%\n"
     ]
    }
   ],
   "source": [
    "Y_probs_train = label_model.predict_proba(L=L_train)\n",
    "\n",
    "Y_preds_train = probs_to_preds(probs=Y_probs_train)\n",
    "\n",
    "words_train = [row.text for i, row in train.iterrows()]\n",
    "words_valid = [row.text for i, row in valid.iterrows()]\n",
    "words_test = [row.text for i, row in test.iterrows()]\n",
    "\n",
    "vectorizer = TfidfVectorizer(ngram_range=(2,2))\n",
    "X_train = vectorizer.fit_transform(words_train)\n",
    "X_valid = vectorizer.transform(words_valid)\n",
    "X_test = vectorizer.transform(words_test)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB().fit(X_train, Y_preds_train_filtered)\n",
    "      \n",
    "print(f\"Test Accuracy: {classifier.score(X=X_test, y=Y_test) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
